{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lartmann/deepfake_detection_project/blob/main/NVB_main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3msDAHK3WjKu"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UcM0RCcXVcFM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Import matplotlib libraries\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzngMpbtF9AK"
      },
      "outputs": [],
      "source": [
        "# import helper functions from my github\n",
        "!wget https://raw.githubusercontent.com/lartmann/deepfake_detection_project/main/ComputerVision/helper_functions_CV.py\n",
        "from helper_functions_CV import plot_loss_curves, plot_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmz7YFLpEoAF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3iKwkTuRsV7"
      },
      "source": [
        "# Computer Vision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ0oNwZE_QyF"
      },
      "source": [
        "### F2F: Load numpy arrays and combine to tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YmqkBkXGAWc2"
      },
      "outputs": [],
      "source": [
        "# Set Hyperparameters\n",
        "BATCH_SIZE = 32 # small BatchSize to aviod ResourceExhaustionError\n",
        "SHUFFLE_BUFFER_SIZE = 42\n",
        "NUMBER_VIDEOS = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIX5WKy7Ne5u"
      },
      "outputs": [],
      "source": [
        "f2f_path = '/content/drive/MyDrive/nvb/F2F'\n",
        "\n",
        "count = 0\n",
        "for np_file in os.listdir(f2f_path):\n",
        "  if np_file.endswith('mp4.npz'):\n",
        "    count += 1\n",
        "    if count == 1:\n",
        "      file_np = np.load(f'{f2f_path}/{np_file}', allow_pickle=True)['data'] # Load file\n",
        "      file_np = np.reshape(file_np, ( len(file_np)*10, 5, 300, 300, 3))\n",
        "      file_tensor = tf.convert_to_tensor(file_np) # convert np to tensor\n",
        "      labels_tensor = tf.expand_dims(tf.convert_to_tensor(np.array([0] * len(file_np))), axis=1) # create labels\n",
        "      f2f_data = tf.data.Dataset.from_tensor_slices((file_np, labels_tensor)) # create dataset from values and labels\n",
        "      print(file_tensor.shape)\n",
        "      print(labels_tensor.shape)\n",
        "    elif count <= NUMBER_VIDEOS:\n",
        "      file_np = np.load(f'{f2f_path}/{np_file}', allow_pickle=True)['data'] # Load file\n",
        "      file_np = np.reshape(file_np, (len(file_np)*10, 5, 300, 300, 3))  \n",
        "      file_tensor = tf.convert_to_tensor(file_np) # convert np to tensor\n",
        "      labels_tensor = tf.expand_dims(tf.convert_to_tensor(np.array([0] * len(file_np))), axis=1) # create labels\n",
        "      current = tf.data.Dataset.from_tensor_slices((file_np, labels_tensor)) # create dataset from values and labels\n",
        "      f2f_data = f2f_data.concatenate(current) # append current dataset to the rest\n",
        "    else:\n",
        "      break\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvOTiVdlVgDf"
      },
      "source": [
        "### original: load numpy arrays and combine to tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dEGfcWjQVqXZ"
      },
      "outputs": [],
      "source": [
        "original_path = '/content/drive/MyDrive/nvb/original'\n",
        "count = 0\n",
        "for np_file in os.listdir(original_path):\n",
        "  count += 1\n",
        "  if count == 1:\n",
        "    file_np = np.load(f'{original_path}/{np_file}', allow_pickle=True)['data'] # Load file\n",
        "    file_np = np.reshape(file_np, (len(file_np)*10, 5, 300, 300, 3))\n",
        "    file_tensor = tf.convert_to_tensor(file_np) # convert np to tensor\n",
        "    labels_tensor = tf.expand_dims(tf.convert_to_tensor(np.array([1] * len(file_np))), axis=1) # create labels\n",
        "    original_data = tf.data.Dataset.from_tensor_slices((file_np, labels_tensor)) # create dataset\n",
        "  elif count <= NUMBER_VIDEOS:\n",
        "    file_np = np.load(f'{original_path}/{np_file}', allow_pickle=True)['data'] # Load file\n",
        "    file_np = np.reshape(file_np, (len(file_np)*10, 5, 300, 300, 3))\n",
        "    file_tensor = tf.convert_to_tensor(file_np) # convert np to tensor\n",
        "    labels_tensor = tf.expand_dims(tf.convert_to_tensor(np.array([1] * len(file_np))), axis=1) # create labels\n",
        "    current = tf.data.Dataset.from_tensor_slices((file_np, labels_tensor)) # create dataset of current tensor\n",
        "    original_data = original_data.concatenate(current) # append current dataset to existing \n",
        "  else:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X96jfEZMMJD5"
      },
      "outputs": [],
      "source": [
        "# split data into test and train \n",
        "\n",
        "train_data_f = f2f_data.take(int(len(f2f_data)*0.8))\n",
        "test_data_f = f2f_data.skip(int(len(f2f_data)*0.8))\n",
        "\n",
        "train_data_o = original_data.take(int(len(original_data)*0.8)) \n",
        "test_data_o = original_data.skip(int(len(original_data)*0.8))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVqQnxbhN9OI",
        "outputId": "e91ff07a-1109-481a-b5d3-b3e448eb97c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of clips in training data: 8960\n",
            "Number of clips in test data: 2240\n"
          ]
        }
      ],
      "source": [
        "train_data = train_data_f.concatenate(train_data_o).shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "test_data = test_data_f.concatenate(test_data_o).shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "print(f\"Number of clips in training data: {train_data.cardinality().numpy() * BATCH_SIZE}\")\n",
        "print(f\"Number of clips in test data: {test_data.cardinality().numpy() * BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1qDwTCeb1oA"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "pMGLels1nOqe"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils import validation\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv3D, MaxPool3D, Activation, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAL-SOIeb6sI"
      },
      "source": [
        "## Base Model\n",
        "basic CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "zFSwjP02b4Tw"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "model_1 = Sequential([\n",
        "  Input(shape=[5, 300, 300, 3], dtype=tf.float16),\n",
        "  Flatten(input_shape = (5,300,300,3)),\n",
        "  Dense(10, activation=\"relu\"), # binary activation output\n",
        "  Dense(100, activation=\"relu\"),\n",
        "  Dense(100, activation=\"relu\"),\n",
        "  Dense(1, activation=\"sigmoid\",)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPhahBkKwOOw"
      },
      "outputs": [],
      "source": [
        "# Fit the model\n",
        "history_1 = model_1.fit(train_data,\n",
        "                        validation_data = test_data,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        epochs=10)\n",
        "                        #validation_split=0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dI6e_xpk2laf"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(history_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uML2SrX0I30v"
      },
      "source": [
        "## 3D CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqYBEdas2sEj"
      },
      "outputs": [],
      "source": [
        "# CNN model for video detection\n",
        "model_2 = Sequential([\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  Conv3D(16,(3,3,3), activation=\"relu\", padding = \"same\"),\n",
        "  MaxPool3D(pool_size=(2, 2, 2)),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  Conv3D(32,(3,3,3), activation=\"relu\", padding = \"same\"),\n",
        "  Conv3D(16,(3,1,1), activation=\"relu\", padding = \"same\"),\n",
        "  tf.keras.layers.BatchNormalization(),\n",
        "  Flatten(input_shape = (5,300,300,3)),\n",
        "  Dense(256, activation=\"relu\"),\n",
        "  Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=Adam(),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHM9-6z8y1Kh"
      },
      "outputs": [],
      "source": [
        "history_2 = model_2.fit(train_data,\n",
        "                        validation_data = test_data,\n",
        "                        batch_size=BATCH_SIZE,\n",
        "                        epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFzQgtZEzsOC"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fOpbrWERUmr"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(history_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgtsOJSeAAT9"
      },
      "source": [
        "## Movinet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-AWt7nJ_zj7"
      },
      "outputs": [],
      "source": [
        "!pip install remotezip tqdm opencv-python==4.5.2.52 opencv-python-headless==4.5.2.52 tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbQNYLyVEGld"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import random\n",
        "import pathlib\n",
        "import itertools\n",
        "import collections\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import remotezip as rz\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "# Import the MoViNet model from TensorFlow Models (tf-models-official) for the MoViNet model\n",
        "from official.projects.movinet.modeling import movinet\n",
        "from official.projects.movinet.modeling import movinet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQgi48PSEc9A"
      },
      "outputs": [],
      "source": [
        "gru = layers.GRU(units=4, return_sequences=True, return_state=True)\n",
        "\n",
        "inputs = tf.random.normal(shape=[1, 10, 8]) # (batch, sequence, channels)\n",
        "\n",
        "result, state = gru(inputs) # Run it all at once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l940REgCExq6",
        "outputId": "a00039c4-90ca-4f82-fa5d-375859987ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "first_half, state = gru(inputs[:, :5, :])   # run the first half, and capture the state\n",
        "second_half, _ = gru(inputs[:,5:, :], initial_state=state)  # Use the state to continue where you left off.\n",
        "\n",
        "print(np.allclose(result[:, :5,:], first_half))\n",
        "print(np.allclose(result[:, 5:,:], second_half))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gC1EBiCAIJQ"
      },
      "outputs": [],
      "source": [
        "model_id = 'a5'\n",
        "resolution = 300\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "backbone = movinet.Movinet(model_id=model_id)\n",
        "backbone.trainable = False\n",
        "\n",
        "model = movinet_model.MovinetClassifier(backbone=backbone, num_classes = 600)\n",
        "model.build([None, None, None, None, 3])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldTbmIeITvXF"
      },
      "outputs": [],
      "source": [
        "# Load pre-trained weights\n",
        "!wget https://storage.googleapis.com/tf_model_garden/vision/movinet/movinet_a5_base.tar.gz -O movinet_a5_base.tar.gz -q\n",
        "!tar -xvf movinet_a5_base.tar.gz\n",
        "\n",
        "checkpoint_dir = f'movinet_{model_id}_base'\n",
        "checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "checkpoint = tf.train.Checkpoint(model=model)\n",
        "status = checkpoint.restore(checkpoint_path)\n",
        "status.assert_existing_objects_matched()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvclAH82r052"
      },
      "outputs": [],
      "source": [
        "def build_classifier(batch_size, num_frames, resolution, backbone, num_classes):\n",
        "  \"\"\"Builds a classifier on top of a backbone model.\"\"\"\n",
        "  model = movinet_model.MovinetClassifier(\n",
        "      backbone=backbone,\n",
        "      num_classes=num_classes\n",
        "      )\n",
        "  model.build([batch_size, num_frames, resolution, resolution, 3])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7glA4Yy-p19"
      },
      "outputs": [],
      "source": [
        "movinet = build_classifier(32, 5, 300, backbone, 2)\n",
        "\n",
        "movinet.trainable = True\n",
        "\n",
        "# freeze all blocks except the last\n",
        "for layer in movinet.layers[:-1]:\n",
        "  layer.trainable = False\n",
        "\n",
        "\n",
        "\n",
        "movinet.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=Adam(learning_rate = 0.01),\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dynXywU_GE_"
      },
      "outputs": [],
      "source": [
        "history_3 = model.fit(train_data,\n",
        "                        validation_data = test_data,\n",
        "                        epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFVQiJg0Ixe1"
      },
      "outputs": [],
      "source": [
        "plot_accuracy(history_3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}