{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8wKBQPf8eNuEzV5RqpPMc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lartmann/deepfake_detection_project/blob/main/MediaPipe/NVB_Landmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcM0RCcXVcFM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "#from tensorflow_docs.vis import embed\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# Import matplotlib libraries\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmz7YFLpEoAF"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uejp1sxVUGK"
      },
      "source": [
        "# Landmark approach\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akdOP_JS1usd"
      },
      "outputs": [],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Erf4eWiRVXhN"
      },
      "outputs": [],
      "source": [
        "!wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/float16/4?lite-format=tflite\n",
        "input_size = 192\n",
        "interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
        "interpreter.allocate_tensors()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apesy-joAPx9"
      },
      "outputs": [],
      "source": [
        "# 2. video\n",
        "vidcap = cv2.VideoCapture('test2.mp4')\n",
        "success,image = vidcap.read()\n",
        "count = 0\n",
        "#out2 = main_visualize(image)\n",
        "while success:\n",
        "  #out2 = tf.concat([out2, main_visualize(image)], axis=0)\n",
        "  #cv2.imwrite(\"output/frame%d.jpg\" % count, out)     # save frame as JPEG file      \n",
        "  #success,image = vidcap.read()\n",
        "  print('Read a new frame: ', success)\n",
        "  count += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nb18d98FT0Fe"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# change Working directory to the video folder\n",
        "os.chdir('Deepfake-Detection-Challenge/train_sample_videos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDVcKnDeSPaA"
      },
      "outputs": [],
      "source": [
        "# load labels from json file\n",
        "with open('metadata.json','r') as j:\n",
        "     labels = json.loads(j.read())\n",
        "labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbnCoZg8abDl"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "# loop throug all the files in a \n",
        "for video in os.listdir():\n",
        "  if video.endswith('.mp4'):\n",
        "    v = cv2.VideoCapture(video)\n",
        "    imgs = video_to_images(v)\n",
        "    o = extract_landmarks(imgs)\n",
        "    # create first df \n",
        "    if count == 0:\n",
        "      dfs = join_image_dfs(o)\n",
        "      dfs['label'] = labels[video]['label']\n",
        "      dfs['VideoId'] = video\n",
        "      count += 1\n",
        "    # append to previous df\n",
        "    else:\n",
        "      df = join_image_dfs(o)\n",
        "      df['label'] = labels[video]['label']\n",
        "      df['VideoId'] = video\n",
        "      dfs = pd.concat([dfs, df])\n",
        "      count += 1\n",
        "  #if count > 5:\n",
        "   # break\n",
        "  print('done ' + str(count) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndfSZz9soEMA"
      },
      "outputs": [],
      "source": [
        "dfs.to_csv('out1.csv')\n",
        "!cp out1.csv \"/content/drive/My Drive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3U_aWkUAcKX"
      },
      "outputs": [],
      "source": [
        "dfs_nona = dfs.dropna()\n",
        "dfs_nona = dfs_nona.reset_index(drop=True)\n",
        "dfs_nona.to_csv('out_nona.csv')\n",
        "!cp out_nona.csv \"/content/drive/My Drive/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMldFjmwow7o"
      },
      "outputs": [],
      "source": [
        "dfs_nona"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6pgHol91GQE"
      },
      "source": [
        "##### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_b9VKPxnaNn"
      },
      "outputs": [],
      "source": [
        "v_fake = cv2.VideoCapture('etmcruaihe.mp4')\n",
        "v_original = cv2.VideoCapture('afoovlsmtx.mp4')\n",
        "\n",
        "imgs_fake = video_to_images(v_fake)\n",
        "imgs_original = video_to_images(v_original)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZ9XmEsJbm5C"
      },
      "outputs": [],
      "source": [
        "#output = draw_landmarks_on_img(imgs)\n",
        "output_fake = extract_landmarks(imgs_fake)\n",
        "output_original = extract_landmarks(imgs_original)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_piNZScZ8T5"
      },
      "outputs": [],
      "source": [
        "video_df_fake = join_image_dfs(output_fake)\n",
        "video_df_original = join_image_dfs(output_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "eTQsW0FC3JAj",
        "outputId": "0e49e5ff-9c8a-4a35-c3f2-c8c0b3b915c2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0f1b3eb8-0775-4e6b-b0a2-c493ac4c320f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x_0</th>\n",
              "      <th>y_0</th>\n",
              "      <th>z_0</th>\n",
              "      <th>x_1</th>\n",
              "      <th>y_1</th>\n",
              "      <th>z_1</th>\n",
              "      <th>x_2</th>\n",
              "      <th>y_2</th>\n",
              "      <th>z_2</th>\n",
              "      <th>x_3</th>\n",
              "      <th>...</th>\n",
              "      <th>z_474</th>\n",
              "      <th>x_475</th>\n",
              "      <th>y_475</th>\n",
              "      <th>z_475</th>\n",
              "      <th>x_476</th>\n",
              "      <th>y_476</th>\n",
              "      <th>z_476</th>\n",
              "      <th>x_477</th>\n",
              "      <th>y_477</th>\n",
              "      <th>z_477</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Series name</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>original</th>\n",
              "      <td>0.401152</td>\n",
              "      <td>0.471183</td>\n",
              "      <td>-0.037070</td>\n",
              "      <td>0.402029</td>\n",
              "      <td>0.454824</td>\n",
              "      <td>-0.050685</td>\n",
              "      <td>0.403437</td>\n",
              "      <td>0.462373</td>\n",
              "      <td>-0.032038</td>\n",
              "      <td>0.393824</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018203</td>\n",
              "      <td>0.448639</td>\n",
              "      <td>0.424146</td>\n",
              "      <td>0.018203</td>\n",
              "      <td>0.439120</td>\n",
              "      <td>0.428233</td>\n",
              "      <td>0.018203</td>\n",
              "      <td>0.448677</td>\n",
              "      <td>0.432417</td>\n",
              "      <td>0.018203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fake</th>\n",
              "      <td>0.402926</td>\n",
              "      <td>0.471003</td>\n",
              "      <td>-0.038333</td>\n",
              "      <td>0.399389</td>\n",
              "      <td>0.453024</td>\n",
              "      <td>-0.051811</td>\n",
              "      <td>0.401056</td>\n",
              "      <td>0.460871</td>\n",
              "      <td>-0.033252</td>\n",
              "      <td>0.391555</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017947</td>\n",
              "      <td>0.448014</td>\n",
              "      <td>0.423959</td>\n",
              "      <td>0.017947</td>\n",
              "      <td>0.438819</td>\n",
              "      <td>0.428123</td>\n",
              "      <td>0.017947</td>\n",
              "      <td>0.447709</td>\n",
              "      <td>0.432381</td>\n",
              "      <td>0.017947</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows Ã— 1434 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f1b3eb8-0775-4e6b-b0a2-c493ac4c320f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f1b3eb8-0775-4e6b-b0a2-c493ac4c320f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f1b3eb8-0775-4e6b-b0a2-c493ac4c320f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                  x_0       y_0       z_0       x_1       y_1       z_1  \\\n",
              "Series name                                                               \n",
              "original     0.401152  0.471183 -0.037070  0.402029  0.454824 -0.050685   \n",
              "fake         0.402926  0.471003 -0.038333  0.399389  0.453024 -0.051811   \n",
              "\n",
              "                  x_2       y_2       z_2       x_3  ...     z_474     x_475  \\\n",
              "Series name                                          ...                       \n",
              "original     0.403437  0.462373 -0.032038  0.393824  ...  0.018203  0.448639   \n",
              "fake         0.401056  0.460871 -0.033252  0.391555  ...  0.017947  0.448014   \n",
              "\n",
              "                y_475     z_475     x_476     y_476     z_476     x_477  \\\n",
              "Series name                                                               \n",
              "original     0.424146  0.018203  0.439120  0.428233  0.018203  0.448677   \n",
              "fake         0.423959  0.017947  0.438819  0.428123  0.017947  0.447709   \n",
              "\n",
              "                y_477     z_477  \n",
              "Series name                      \n",
              "original     0.432417  0.018203  \n",
              "fake         0.432381  0.017947  \n",
              "\n",
              "[2 rows x 1434 columns]"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Total number of columns (1434) exceeds max_columns (20) limiting to first (20) columns.\n"
          ]
        }
      ],
      "source": [
        "# compare fake and real\n",
        "#video_df_original.compare(video_df_fake)\n",
        "#video_df_fake\n",
        "\n",
        "df_con = pd.concat([video_df_original, video_df_fake], keys=['original', 'fake'],names=['Series name', 'Row ID'])\n",
        "df_con.groupby('Series name').mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaQ1ucyGoLT6"
      },
      "source": [
        "#### Face Forensic Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksl_pAdqoPCZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/faceforensics/manipulated_sequences/Face2Face/c23/videos')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqCoNXaSobNX"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "dfs_list_fake = []\n",
        "# loop throug all the files in a \n",
        "for video in os.listdir():\n",
        "  if video.endswith('.mp4'):\n",
        "    v = cv2.VideoCapture(video)\n",
        "    imgs = video_to_images(v)\n",
        "    o = extract_landmarks(imgs)\n",
        "    df = join_image_dfs(o)\n",
        "    df['VideoId'] = video\n",
        "    #dfs = pd.concat([dfs, df])\n",
        "    dfs_list_fake.append(df)\n",
        "    count += 1\n",
        "  if count > 50:\n",
        "    break\n",
        "  print('done ' + str(count) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3ZqPuwsJExb"
      },
      "source": [
        "https://www.tensorflow.org/guide/ragged_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcMCHHKIF0XQ"
      },
      "outputs": [],
      "source": [
        "dfs_transformed_list_fake = transform_dfs(dfs_list_fake)\n",
        "\n",
        "# ragged tensro shape: (num_videos, num_frames, num_landmarks(478), num_cordinates(3))\n",
        "array_fake = [x.to_numpy() for x in dfs_transformed_list_fake]\n",
        "#data_fake = tf.ragged.constant(array_fake, dtype=float)\n",
        "#data_fake.bounding_shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZQp3Q6bmvrd",
        "outputId": "d487bed9-8940-432e-f7c6-67bb1579403d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "#np.array(array_fake)\n",
        "np.savez_compressed('/content/drive/MyDrive/data_face2face_50.npz', fake = np.array(array_fake))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0gznDovIkQN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#print(array_fake.shape)\n",
        "np.load('/content/drive/MyDrive/data_face2face_100.npz', allow_pickle=True)['fake']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs1-A22YMGg3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/faceforensics/original_sequences/youtube/c23/videos')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8y9LobvONHT1"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "dfs_list_original = []\n",
        "# loop throug all the files in a \n",
        "for video in os.listdir():\n",
        "  if video.endswith('.mp4'):\n",
        "    v = cv2.VideoCapture(video)\n",
        "    imgs = video_to_images(v)\n",
        "    o = extract_landmarks(imgs)\n",
        "    df = join_image_dfs(o)\n",
        "    df['VideoId'] = video\n",
        "    #dfs = pd.concat([dfs, df])\n",
        "    dfs_list_original.append(df)\n",
        "    count += 1\n",
        "  if count > 50:\n",
        "    break\n",
        "  print('done ' + str(count) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66CUTLgPM0U2",
        "outputId": "1f42a174-ba2c-4ac8-8c69-0a5b533208d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "dfs_transformed_list_original = transform_dfs(dfs_list_original)\n",
        "array_original = [x.to_numpy() for x in dfs_transformed_list_original]\n",
        "# ragged tensor shape: (num_videos, num_frames, num_landmarks(478), num_cordinates(3))\n",
        "#data_original = tf.ragged.constant([x.to_numpy() for x in dfs_transformed_list_original], dtype='float32' )\n",
        "#data_original.bounding_shape()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQIFSJVigtY_",
        "outputId": "af95d4bf-1197-4cc4-b9c9-979825dc0c32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "np.savez_compressed('/content/drive/MyDrive/data_face2face_original_50.npz', original = np.array(array_original))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzRb0syDsjDq"
      },
      "outputs": [],
      "source": [
        "data_fake = tf.ragged.constant(np.load('/content/drive/MyDrive/data_face2face_50.npz', allow_pickle=True)['fake'], dtype='float32' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP8r-aTVsmZE"
      },
      "outputs": [],
      "source": [
        "data_original = tf.ragged.constant(np.load('/content/drive/MyDrive/data_face2face_original_50.npz', allow_pickle=True)['original'], dtype='float32' )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGCCbwe5RDpe"
      },
      "outputs": [],
      "source": [
        "data = tf.concat([data_fake, data_original], axis = 0)\n",
        "data_fake = []\n",
        "data_original = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7Nneue3tXN8"
      },
      "outputs": [],
      "source": [
        "y = tf.constant([0]*51 + [1]*51, dtype='int32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x9HwJ7Gpyzzl"
      },
      "outputs": [],
      "source": [
        "data = data.to_sparse()\n",
        "data = tf.sparse.to_dense(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pylpe02vS-iO",
        "outputId": "fc736989-e65a-4fcd-abd3-985240c6528a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "TensorShape([102, 1497, 478, 3])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obNkmndLwjoK"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP8ymV4eCNRD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, y, shuffle=True, random_state=42, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-Jz5rbSCTwZ"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "# ragged_input = tf.keras.layers.Input(shape=[], dtype=tf.float32, ragged=True)\n",
        "\n",
        "model_4 = tf.keras.Sequential([\n",
        "\ttf.keras.layers.Input(shape=[1497, 478, 3], dtype='float32'),\n",
        "\ttf.keras.layers.Dense(10, activation = \"relu\"),\n",
        "\ttf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_4.compile(loss = \"binary_crossentropy\",\n",
        "\t\t\t\toptimizer = tf.keras.optimizers.Adam(),\n",
        "\t\t\t\tmetrics = [\"accuracy\"])\n",
        "\n",
        "history = model_4.fit(tf.sparse.to_dense(data_sparse), labels, epochs = 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3aHY65xhI6P",
        "outputId": "d4508195-e595-41f2-de64-48409552e0db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "7/7 [==============================] - 184s 25s/step - loss: nan - accuracy: 0.5050\n",
            "Epoch 2/5\n",
            "7/7 [==============================] - 170s 24s/step - loss: nan - accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "7/7 [==============================] - 169s 24s/step - loss: nan - accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "7/7 [==============================] - 175s 25s/step - loss: nan - accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "7/7 [==============================] - 168s 24s/step - loss: nan - accuracy: 0.5000\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPool2D, Activation, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create a CNN model (same as Tiny VGG - https://poloclub.github.io/cnn-explainer/)\n",
        "model_1 = Sequential([\n",
        "  Input(shape=[1497, 478, 3], dtype=tf.float32, ragged=False),\n",
        "  Conv2D(filters=10, \n",
        "         kernel_size=3, # can also be (3, 3)\n",
        "         strides=1,\n",
        "         padding=\"valid\",\n",
        "         activation=\"relu\"),\n",
        "         #input_shape=(224, 224, 3)), # first layer specifies input shape (height, width, colour channels)\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  MaxPool2D(pool_size=2, # pool_size can also be (2, 2)\n",
        "            padding=\"valid\"), # padding can also be 'same'\n",
        "  Conv2D(10, 3, activation=\"relu\"),\n",
        "  Conv2D(10, 3, activation=\"relu\"), # activation='relu' == tf.keras.layers.Activations(tf.nn.relu)\n",
        "  MaxPool2D(2),\n",
        "  Flatten(),\n",
        "  Dense(10, activation=\"relu\"), # binary activation output\n",
        "  Dense(100, activation=\"relu\"),\n",
        "  Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "# Fit the model\n",
        "history_1 = model_1.fit(data,\n",
        "                        y,\n",
        "                        epochs=5)"
      ]
    }
  ]
}